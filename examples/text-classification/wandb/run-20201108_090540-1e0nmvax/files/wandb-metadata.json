{
    "os": "Linux-4.15.0-76-generic-x86_64-with-debian-buster-sid",
    "python": "3.7.9",
    "heartbeatAt": "2020-11-08T17:05:41.599267",
    "startedAt": "2020-11-08T17:05:40.659350",
    "docker": null,
    "gpu": "Tesla V100-SXM2-32GB",
    "gpu_count": 4,
    "cpu_count": 96,
    "cuda": "10.1.243",
    "args": [
        "--model_name_or_path",
        "../../../data/bert-base-cased",
        "--task_name",
        "RTE",
        "--do_train",
        "--do_predict",
        "--do_eval",
        "--max_seq_length",
        "128",
        "--per_gpu_train_batch_size",
        "32",
        "--learning_rate",
        "2e-5",
        "--num_train_epochs",
        "3.0",
        "--output_dir",
        "./tmp/RTE/",
        "--overwrite_output_dir",
        "--evaluate_during_training"
    ],
    "state": "running",
    "codePath": "examples/text-classification/run_glue.py",
    "program": "run_glue.py",
    "git": {
        "remote": "https://github.com/liususan091219/transformers.git",
        "commit": "ec9c02beb4c01f510f28ae93432d058297afe33a"
    },
    "email": null,
    "root": "/data/xliu127/projects/hyperopt/transformers",
    "host": "tmdev",
    "username": "xliu127",
    "executable": "/data/installation/anaconda3/envs/null/bin/python3"
}
